{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0370819f-0f4e-487a-b453-6b90ad76533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import GPT2Config, TFGPT2LMHeadModel\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6612478-3869-41ae-abf1-48b3c9bd6d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at C:/Users/28056/Desktop/研究生/AnimeTAB/AnimeTAB/model_8_6_generation.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# creating the model\n",
    "model = TFGPT2LMHeadModel.from_pretrained('C:/Users/28056/Desktop/研究生/AnimeTAB/AnimeTAB/model_8_6_generation')\n",
    "configs = GPT2Config.from_json_file('C:\\\\Users\\\\28056\\\\Desktop\\\\研究生\\\\AnimeTAB\\\\AnimeTAB\\\\model_8_6_generation\\\\config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ed4632e-065c-4854-a5fa-73422122159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "music_tokenizer = Tokenizer.from_file('C:\\\\Users\\\\28056\\\\Desktop\\\\研究生\\\\AnimeTAB\\\\AnimeTAB\\\\music_tokenizer_8_6.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "700fbc7c-c86b-4941-b857-16209e00abd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TABprocessor import *\n",
    "input_measure = ['<s>4G 5C', 'SUS', 'SUS', 'SUS']\n",
    "def generate_line(input_measure):\n",
    "    \n",
    "    def tokenizer_deprocess(sentence):\n",
    "        '''\n",
    "        希腊字母的逆变换\n",
    "        '''\n",
    "        measure = []\n",
    "        xila = ['t', 'u', 'v', 'w', 'x', 'y', 'z', 'j', 'k']\n",
    "        octave = [' 0', ' 1', ' 2', ' 3', ' 4', ' 5', ' 6', '#', '-']\n",
    "        cus = sentence.split()\n",
    "        for cu in cus:\n",
    "            if cu in [\"[PAD]\", '<s>', '</s>', 'SUS', '[MSK]', '[CLS]', '[EOS]', 'R']:\n",
    "                measure.append(cu)\n",
    "            elif cu == 'Ġ':\n",
    "                measure.append(' ')\n",
    "            else:\n",
    "                for i in range(len(xila)):\n",
    "                    cu = cu.replace(xila[i], octave[i])\n",
    "                cu = cu[1:]\n",
    "                measure.append(cu)\n",
    "        return1 = ''\n",
    "        for i in measure:\n",
    "            return1 += i\n",
    "            \n",
    "        return1 = return1.replace('[CLS]', ' ')\n",
    "        return1 = return1.replace('<s>', ' ')\n",
    "        return1 = return1.replace('[EOS]', ' ')\n",
    "        print(return1)\n",
    "        return return1.split('</s>')\n",
    "    \n",
    "    greek_measure = song_greek([input_measure])\n",
    "    if input_measure[0] != '<s>':\n",
    "        greek_measure = '<s>' + greek_measure\n",
    "    if input_measure[0] != '[CLS]':\n",
    "        greek_measure = '[CLS]' + greek_measure\n",
    "    if input_measure[-1] != '</s>':\n",
    "        greek_measure = greek_measure + '</s>'\n",
    "    print(greek_measure)\n",
    "    input_ids = np.array(music_tokenizer.encode(greek_measure).ids).reshape(-1, 1)\n",
    "    input_ids = tf.convert_to_tensor(input_ids)\n",
    "    \n",
    "    beam_output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=200,\n",
    "    temperature=1.2, \n",
    "    pad_token_id=0,\n",
    "    bos_token_id=4,\n",
    "    eos_token_id=5,\n",
    "    num_beams=3\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return2 = tokenizer_deprocess(music_tokenizer.decode(beam_output[0].numpy()))\n",
    "    return return2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16d7c1de-0acd-4ad5-86ec-aa4bbc153267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####0. Empty.xml\n",
      "#####1. [Air]鸟之诗_10^27B.xml\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\28056\\\\Desktop\\\\研究生\\\\AnimeTAB\\\\AnimeTAB\\\\test\\\\repeattest'\n",
    "songs = readTAB(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adda16e3-6d10-45a7-ba26-743080e6be97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4E 2G', 'SUS', 'SUS', 'SUS', '4E', 'SUS', '4D 2G', '4E 2G', 'SUS', 'SUS', '3D', 'SUS', '3A', 'SUS', '3B', 'SUS']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ad6a12bf-b964-499a-8c5f-cb75d3df5e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = songs[1].vectorization(division=16).pitch[0]\n",
    "def generate_by_measure(measure):\n",
    "\n",
    "    input1 = measure\n",
    "    input1.append('</s>')\n",
    "    head = ['<s>']\n",
    "    head.extend(input1)\n",
    "    sentence = ''\n",
    "    for str1 in head:\n",
    "        sentence += str1\n",
    "        sentence += ' '\n",
    "    sentence = sentence[:-1]\n",
    "    input_ids = np.array(music_tokenizer.encode(sentence).ids).reshape(-1, 1)\n",
    "    input_ids = tf.convert_to_tensor(input_ids)\n",
    "    \n",
    "    beam_output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=200,\n",
    "        temperature=1.2, \n",
    "        pad_token_id=0,\n",
    "        bos_token_id=4,\n",
    "        eos_token_id=5,\n",
    "        num_beams=3，\n",
    "        attention_mask=\n",
    "        )\n",
    "    return beam_output\n",
    "    \n",
    "beam_output = generate_by_measure(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6498a951-5d61-4a25-9d23-a690043cde1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_deprocess(sentence):\n",
    "    '''\n",
    "    希腊字母的逆变换\n",
    "    '''\n",
    "    measure = []\n",
    "    xila = ['t', 'u', 'v', 'w', 'x', 'y', 'z', 'j', 'k']\n",
    "    octave = [' 0', ' 1', ' 2', ' 3', ' 4', ' 5', ' 6', '#', '-']\n",
    "    cus = sentence.split()\n",
    "    for cu in cus:\n",
    "        if cu in [\"[PAD]\", '<s>', '</s>', 'SUS', '[MSK]', '[CLS]', '[EOS]', 'R']:\n",
    "            measure.append(cu)\n",
    "        elif cu == 'Ġ':\n",
    "            measure.append(' ')\n",
    "        else:\n",
    "            for i in range(len(xila)):\n",
    "                cu = cu.replace(xila[i], octave[i])\n",
    "            cu = cu[1:]\n",
    "            measure.append(cu)\n",
    "    return1 = ''\n",
    "    for i in measure:\n",
    "        return1 += i\n",
    "\n",
    "    return1 = return1.replace('[CLS]', ' ')\n",
    "    return1 = return1.replace('<s>', ' ')\n",
    "    return1 = return1.replace('[EOS]', ' ')\n",
    "    print(return1)\n",
    "    return return1.split('</s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "78115508-5749-44f7-b5c0-d6c714605902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_measure(beam_output):\n",
    "    output = music_tokenizer.decode(beam_output[0], skip_special_tokens=False).split(' ')\n",
    "    output = output[output.index('<s>')+1:output.index('</s>')]\n",
    "\n",
    "    sentence = ''\n",
    "    for sen in output:\n",
    "        sentence += sen\n",
    "\n",
    "    sentence = sentence.replace('Ġ', ' ')\n",
    "    return sentence\n",
    "\n",
    "born_measure1 = give_measure(beam_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "256897a7-ca76-481a-a8ae-020200d9a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "input2 = songs[1].vectorization(division=16).pitch[1]\n",
    "beam_output2 = generate_by_measure(input2)\n",
    "born_measure2 = give_measure(beam_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "427a2980-cb1c-4afa-a11c-8a29ff48dbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wD SUS wD SUS xF SUS wD SUS xEwD SUS wD SUS xF SUS xAwD SUS\n",
      "wD SUS wD SUS xF SUS wD SUS xEwD SUS wD SUS xF SUS xAwD SUS\n"
     ]
    }
   ],
   "source": [
    "print(born_measure1)\n",
    "print(born_measure2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990dc9cf-27ae-4d5b-a58d-2e00b8048e95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
