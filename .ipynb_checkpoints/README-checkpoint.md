# AnimeTAB & TABprocessor
AnimeTAB is a musicXML-based guitar tablature dataset. All tracks of AnimeTAB are arranged from anime and video game soundtracks. AnimeTAB is including three following parts:

## Full tracks
About 400+ full tracks are in the *./AnimeTAB/Entire songs* folder. All tracks are derived from the 'export to musicXML' function of Guitarpro7 and labeled with the name of its origin anime/game. 
This dataset are working under CC-We collect these tracks from 
## Track clips
From 400+ full tracks we choose 200+ best quality tracks and cut them into 500+ clips by different musical structures. The clips are in *./AnimeTAB/Clips* folder and the 200+ chosen tracks are in *./AnimeTAB/Clips/Originals* folder. The structure name and begin/end bar numbers are labeled in file names. Four kinds of strucures are included: intro(I), verse(A), chorus(B) and bridge(C).

## TABprocessor
TABprocessor is a lightweight MIR toolkit for information extraction, processing, and analysis functions that is specifically oriented to guitar MusicXML scores generated by GuitarPro. It is designed to allow even code beginners or musicians who do not have strong coding skills get started quickly and have fun with it. A demonstration analysis of AnimeTAB using TABprocessor is listed below:
![Demonstration analysis](https://github.com/amamiya-yuuko/AnimeTAB/blob/main/Demonstration%20analysis.jpg)


# TABprocessor

To use TABprocessor, just:
```
from TABprocessor import *
songs = readTAB(path)
```
Then the **readTAB** function will read all the MusicXML tablatures in the path and return a list of *Tablature* objects.
A *Tablature* object has four attributes: *pitch*, *finger*, *time* and *info*. Try this:

```
song = songs[0]
print('Pitch of first measure: {}'.format(song.pitch[0]))
print('Fingering of first measure: {}'.format(song.finger[0]))
print('Time of first measure: {}'.format(song.time[0]))
print('Metamessage: {}'.format(song.info))
```
```
Pitch of first measure: ['3A 3E 3C 2F', '3A 3F 3C 2F']
Fingering of first measure: ['(3,2) (4,2) (5,3) (6,1)', '(3,2) (4,3) (5,3) (6,1)']
Time of first measure: [2.0, 2.0]
Name: 幻化成风
Origin: 千与千寻
```

Other functions including:
## Vectorization
```
print('Pitch of first measure:{}'.format(song.pitch[0]))
print('Time of first measure:{}'.format(song.time[0]))

vec_song = song.vectorization(division=16)
print('Vectorize result:{}'.format(vec_song.pitch[0]))
```

```
Pitch of first measure:['3A 3E 3C 2F', '3A 3F 3C 2F']
Time of first measure:[2.0, 2.0]
Vectorize result:['3A 3E 3C 2F', 'SUS', 'SUS', 'SUS', 'SUS', 'SUS', 'SUS', 'SUS', '3A 3F 3C 2F', 'SUS', 'SUS', 'SUS', 'SUS', 'SUS', 'SUS', 'SUS']
```
The *vectorization* method will return a list of notes and use 'SUS' to fill different note time. The element number of the list relies on the *division* argument, i.e. the time guranularity. 
This will be a useful preprocess for end-to-end seq2seq models.

## Special events detect
```
skills_detect(noteNode)
```
The *skills_detect* function return a dict of whether there is a possible special event in a note node. For now it supports:
```
special_skills = {        
        'pitch':False, #if it has a pitch
        'duration':False, #if it has a duration
        'rest':False, #if it is a rest
        'dot':False, #if it has a dot
        'tie':True, 
        'chord':False, #if this note is sound at the same time as former note
        'tuplet':False,  # -3-
        'grace':False,  
        'artificial':False,   #artificial harmonic
        'natural':False, #natural harmonic
        'mute':False  #if it's a dead note
    }
```
and users can add the dict for more special events.

## Key detection and shift

```
key = song.key()
new_song = song.key_shift(new_key)
```

The *key()* method suspect the key by the distribution of all pitches. Uppercase letters indicate major keys, lowercase letters indicate minor keys.
The *key_shift(new_key)* method will transfer the pitch to the new key and return the pitch. 


## Chord recognition
```
chord_recognize(pitch_cluster)
```

This function recognize a chord's type by the in-chord intervals. For now it supports:

```
    '''
    maj: interval loops as 435 435 435 or 75 or 48 or 39 semitones
    min: 345 345 345
    maj7: ， 4341 4341 4341 or 471
    m7: 3432 3432 3432 or 732
    7:  4332 4332 4332
    aug: 444 444 444
    dim: 326 326 326
    '''
```

## Convert between MIDI value/encoded pitch/finger positions
```
str2midi(str1)
midi2str(midivalue)
finger2midi(finger)
midi2finger(midivalue)
```
Special tunings also supported

## Root and melody extraction
```
print('Origin pitch: {}'.format(songs[2].pitch[0]))
print('Origin finger: {}'.format(songs[2].finger[0]))

root_song = songs[2].root_and_melody()
print('Bassline and melody:{}'.format(root_song.pitch[0]))
```

```
Origin pitch: ['3C', '4C 3G', '4E']
Origin finger: ['(5,3)', '(2,1) (3,0)', '(1,0)']
Bassline and melody:['3C', '4C', '4E']
```
The *root_and_melody* method will detect the bassline and melody of a tablature, and return a new *Tablature* object with only the bassline and melody.
## xml files output
```
generateTAB(song, path)
```
Write the object into a MusicXML file

################


Contact us:Yuecheng_Zhou@cuc.edu.cn
